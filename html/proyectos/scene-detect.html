<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- css -->
  <link rel="stylesheet" href="../../estilos\estilo_principal.css">
  <!-- <link rel="stylesheet" href="../../estilos\readme.css"> -->
  <link rel="stylesheet" href="https://bootswatch.com/4/darkly/bootstrap.min.css">
  <link rel="stylesheet" href="../../estilos\readme.css">
  
  <title>DaVinci Resolve</title>
</head>
<body>
  <ul class="topnav">
    <li><a class="active" href="index.html">Inicio</a></li>
    <li><a href="..\html\proyectos.html">Proyectos y blogs</a></li>
    <li><a href="#contact">Galeria</a></li>
    <li class="right"><a href="#about">About</a></li>
  </ul>


  <main>
<h1 id="deteccion-de-planos">deteccion-de-planos</h1>
<p>Detectar y separar un video por planos y reconocer el contenido.</p>
<p>Llamando a app.py desde el cmd puedes separar un video por escenas junto a datos de estas escenas.</p>
<p>Se pueden emplear diferentes modelos de deep learning como inception o vgg16.</p>
<p>parametros de entrada:</p>
<ul>
<li><code>--video_path, -v</code>: path to the video</li>
<li><code>--csv, -csv</code>: csv name</li>
<li><code>--images, -im</code>: save images high_res</li>
<li><code>--prediction_number, -pn</code>: number of predictions from most probable to less</li>
<li><code>--model, -m</code>: name of pre-trained network to use</li>
<li><code>--output, -out</code>: Folder where images and html will be stored</li>
</ul>
<p>El único parametro necesario es el video, los otros se definiran en funcion de este </p>
<h2 id="anaconda">Anaconda</h2>
<p>crear entorno en anaconda prompt con:<br />
<code>conda env create -n m1 -f environment.yaml</code></p>
<h2 id="ejemplos-y-uso">Ejemplos y uso</h2>
<p><code>python app.py -v video_path.mp4 -csv custom_name  -im False -pn 3 -m resnet -out None</code><br />
o<br />
<code>python app.py -v video_path.mp4</code></p>
<p>La salida se guardara en una carpeta con el nombre del video por defecto o con el nombre de <code>-out</code> si este es declarado en la llamada.</p>
<h2 id="salida">Salida</h2>
<p>Se generarán: </p>
<ul>
<li>Un csv</li>
<li>Un html con imagenes y datos adicionales, </li>
<li>Carpeta con imagenes low_res para el html</li>
<li>carpeta con imagenes high_res si <code>--images, -im</code> == True</li>
</ul>
<p><a href="scene-detect/NG.html">Ejemplo de output con un video</a></p>
<p><a href="https://github.com/carlesmatoses/deteccion-de-planos">Repositorio GITHUB</a></p>

  </main>
</body>
</html>